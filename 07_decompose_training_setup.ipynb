{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb0207e2",
   "metadata": {},
   "source": [
    "# Breaking down the training setup\n",
    "\n",
    "This is a \"descontruction\" of what happens in `train_lighting.py`. We keep only the essential parts. Easy to hack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27401353",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45053/3636360845.py:6: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize(config_path=\"conf\", job_name=\"notebook_app\"):\n",
      "/home/jackd/source/egolifter/.venv/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'train': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from hydra import initialize, compose\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "# Initialize Hydra with the directory where your config lives.\n",
    "# Note that hydra will tkae care of composing all our disparate config files\n",
    "with initialize(config_path=\"conf\", job_name=\"notebook_app\"):\n",
    "    # Compose the configuration, using \"train\" as the config name.\n",
    "    cfg = compose(config_name=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc3a978a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt:\n",
      "  iterations: 30000\n",
      "  val_every_n_steps: 5000\n",
      "  ckpt_every_n_steps: 10000\n",
      "  position_lr_init: 0.00016\n",
      "  position_lr_final: 1.6e-06\n",
      "  position_lr_delay_mult: 0.01\n",
      "  position_lr_max_steps: 30000\n",
      "  color_lr: 0.0025\n",
      "  feature_lr: 0.0025\n",
      "  opacity_lr: 0.05\n",
      "  scaling_lr: 0.005\n",
      "  rotation_lr: 0.001\n",
      "  percent_dense: 0.01\n",
      "  lambda_dssim: 0.2\n",
      "  densification_interval: 100\n",
      "  opacity_reset_interval: 3000\n",
      "  densify_from_iter: 500\n",
      "  densify_until_iter: 15000\n",
      "  densify_grad_threshold: 0.0002\n",
      "  densify_grad_feat_scale: 1.0\n",
      "  lambda_feat_mse: 1.0\n",
      "  warm_up: 3000\n",
      "  deform_lr_max_steps: 40000\n",
      "model:\n",
      "  name: vanilla\n",
      "  sh_degree: 3\n",
      "  dim_extra: 0\n",
      "  white_background: true\n",
      "  contr_weight_mode: null\n",
      "  contr_weight_thresh: null\n",
      "ip: 127.0.0.1\n",
      "port: 6009\n",
      "debug_from: -1\n",
      "detect_anomaly: false\n",
      "quiet: false\n",
      "start_checkpoint: null\n",
      "load_ply: null\n",
      "render_video: false\n",
      "exp_name: exp\n",
      "output_root: ./output\n",
      "seed: 42\n",
      "gpus: 1\n",
      "skip_test: false\n",
      "log_cam_stats: false\n",
      "wandb:\n",
      "  project: 3dgs\n",
      "  entity: null\n",
      "  save_root: null\n",
      "  save_dir: ${scene.model_path}\n",
      "scene:\n",
      "  data_root: null\n",
      "  scene_name: null\n",
      "  source_path: ${scene.data_root}/${scene.scene_name}\n",
      "  model_path: ${output_root}/${scene.scene_name}/${model.name}_${exp_name}\n",
      "  images: images\n",
      "  resolution: -1\n",
      "  stride: 1\n",
      "  camera_name: rgb\n",
      "  pcd_stride: 1\n",
      "  aggregate: false\n",
      "  use_hdr: false\n",
      "  load_seg_mask: ${lift.use_contr}\n",
      "  num_workers: 12\n",
      "  no_novel: false\n",
      "  all_seen_train: false\n",
      "  eval: true\n",
      "lift:\n",
      "  use_contr: false\n",
      "  name: default\n",
      "  contr_dim: ${model.dim_extra}\n",
      "  contr_multilabel: false\n",
      "  sum_out_log: false\n",
      "  sim_exp: 1\n",
      "  det_folder_name: gsa_det_none_sam\n",
      "  temperature: 100.0\n",
      "  lambda_contr: 0.1\n",
      "  n_samples: 4096\n",
      "  lift_delay_n_steps: 0\n",
      "pipe:\n",
      "  convert_SHs_python: false\n",
      "  compute_cov3D_python: false\n",
      "  debug: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now you can use cfg to see what was loaded.\n",
    "print(OmegaConf.to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ba45541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./output/adt/Apartment_release_golden_skeleton_seq100_10s_sample/vanilla_egolifter_notebook_exp\n"
     ]
    }
   ],
   "source": [
    "# Make sure to set the scene name and data root\n",
    "cfg.scene.data_root = \"/home/jackd/source/egolifter/adt_processed\"\n",
    "cfg.scene.scene_name = \"Apartment_release_golden_skeleton_seq100_10s_sample\"\n",
    "cfg.output_root='./output/adt'\n",
    "\n",
    "# Set the experiment name\n",
    "cfg.exp_name='egolifter_notebook_exp'\n",
    "\n",
    "# Set the name of the project for wandb (keep things tiddy)\n",
    "cfg.wandb.project='egolifter_adt'\n",
    "\n",
    "# Sanity check: this should NOT raise an error!\n",
    "print(cfg.scene.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e07d96b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the output directory\n",
    "import os\n",
    "os.makedirs(cfg.scene.model_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5760ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjackdaus\u001b[0m (\u001b[33mjackdaus-george-mason-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for wandb.init()..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./output/adt/Apartment_release_golden_skeleton_seq100_10s_sample/vanilla_egolifter_notebook_exp/wandb/run-20250505_002343-dawt8b41</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jackdaus-george-mason-university/egolifter_adt/runs/dawt8b41' target=\"_blank\">egolifter_notebook_exp</a></strong> to <a href='https://wandb.ai/jackdaus-george-mason-university/egolifter_adt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jackdaus-george-mason-university/egolifter_adt' target=\"_blank\">https://wandb.ai/jackdaus-george-mason-university/egolifter_adt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jackdaus-george-mason-university/egolifter_adt/runs/dawt8b41' target=\"_blank\">https://wandb.ai/jackdaus-george-mason-university/egolifter_adt/runs/dawt8b41</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set up the logger (wandb)\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "\n",
    "# Make the wandb directory\n",
    "os.makedirs(os.path.join(cfg.scene.model_path, \"wandb\"), exist_ok=True)\n",
    "os.makedirs(cfg.wandb.save_dir, exist_ok=True)\n",
    "\n",
    "# Create the logger\n",
    "logger = WandbLogger(\n",
    "    project=cfg.wandb.project, \n",
    "    entity=cfg.wandb.entity,\n",
    "    name=cfg.exp_name,\n",
    "    save_dir=cfg.wandb.save_dir,\n",
    ")\n",
    "\n",
    "# Tell the logger what hyperparameters to log\n",
    "logger.log_hyperparams(OmegaConf.to_container(cfg, resolve=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45b6c067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And save the config to the output directory (OPTIONAL)\n",
    "# This is useful for keeping track of what you ran\n",
    "# OmegaConf.save(cfg, os.path.join(cfg.scene.model_path, \"config.yaml\"), resolve=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55c6cfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found global_points.csv.gz file, assuming Aria data set!\n",
      "Using cameras: {'rgb'}\n",
      "Loaded #3dPoints: 61357\n",
      "Loading the semantic segmentation info\n",
      "Found 170 images for train subset.\n",
      "Found 43 images for valid subset.\n",
      "Found 27 images for valid_novel subset.\n",
      "Found 27 images for test subset.\n",
      "Found 213 images for trainvalid subset.\n",
      "Found 54 images for novel subset.\n",
      "Found 240 images for all subset.\n"
     ]
    }
   ],
   "source": [
    "import lightning as L\n",
    "from scene import Scene\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "L.seed_everything(cfg.seed)\n",
    "\n",
    "# Create a new scene object\n",
    "scene = Scene(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60435888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing VanillaGaussian...\n",
      "VanillaGaussian(\n",
      "  (gaussians): GsplatModel()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from model import get_model\n",
    "\n",
    "# Load the model. This is one of our LightningModules (i.e., VanillaGaussian, Unc2DUnet, etc.)\n",
    "model = get_model(cfg, scene)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2ed5ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the model to print the parameters\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6343b12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of points at initialisation :  9164\n"
     ]
    }
   ],
   "source": [
    "# This will load an initial point cloud. The point cloud is loaded from scene.scene_info.point_cloud, which was initialized\n",
    "# above in the Scene class. Internally, that comes from global_points.csv.gz file (Aria dataset only; other datasets \n",
    "# init this differently).\n",
    "model.init_or_load_gaussians(\n",
    "    scene.scene_info.point_cloud,\n",
    "    scene.scene_info.nerf_normalization[\"radius\"], # NOTE: not sure that this does... \n",
    "    cfg.scene.model_path,\n",
    "    load_iteration = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f38eb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaussians._xyz torch.Size([9164, 3])\n",
      "gaussians._features_dc torch.Size([9164, 1, 3])\n",
      "gaussians._features_rest torch.Size([9164, 15, 3])\n",
      "gaussians._features_extra torch.Size([9164, 0])\n",
      "gaussians._scaling torch.Size([9164, 3])\n",
      "gaussians._rotation torch.Size([9164, 4])\n",
      "gaussians._opacity torch.Size([9164, 1])\n"
     ]
    }
   ],
   "source": [
    "# Loop over the model to print the parameters\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b34556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data loader. This is a PyTorch DataLoader object that will load the data for training.\n",
    "train_loader = scene.get_data_loader(\"train\", shuffle=True, num_workers=cfg.scene.num_workers)\n",
    "valid_loader = scene.get_data_loader(\"valid\", shuffle=False, num_workers=cfg.scene.num_workers)\n",
    "valid_novel_loader = scene.get_data_loader(\"valid_novel\", shuffle=False, num_workers=cfg.scene.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a7f8b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# Init the trainer\n",
    "trainer = L.Trainer(\n",
    "    max_steps=cfg.opt.iterations,\n",
    "    logger=logger,\n",
    "    check_val_every_n_epoch=None,\n",
    "    val_check_interval = cfg.opt.val_every_n_steps, # validation after every 5000 steps\n",
    "    # callbacks=[checkpoint_callback],\n",
    "    devices=cfg.gpus, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c14c2c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type        | Params | Mode \n",
      "--------------------------------------------------\n",
      "0 | gaussians | GsplatModel | 540 K  | train\n",
      "--------------------------------------------------\n",
      "540 K     Trainable params\n",
      "0         Non-trainable params\n",
      "540 K     Total params\n",
      "2.163     Total estimated model params size (MB)\n",
      "1         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output folder: ./output/adt/Apartment_release_golden_skeleton_seq100_10s_sample/vanilla_egolifter_notebook_exp\n",
      "Setting up for training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38d79542516e4b52b8c864b7f8e1c112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86ff83c1af724147a4bd47179ec9ecfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d865921a2aa40b5bc9034227ae8ddca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00ab437770a4b75802e8a001ec8bd2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c7a3e8ccb85459782c8d1da57c0a4b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "405b0b35cdb8492ebfb45fc06121226b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd45ca4a422b428b91e136624d7262bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60bf5bfb02d94bf098689afb432ad079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=30000` reached.\n"
     ]
    }
   ],
   "source": [
    "# Train the model!\n",
    "trainer.fit(\n",
    "    model=model,\n",
    "    train_dataloaders=train_loader,\n",
    "    val_dataloaders=[valid_loader, valid_novel_loader],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ca029c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "egolifter",
   "language": "python",
   "name": "egolifter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
